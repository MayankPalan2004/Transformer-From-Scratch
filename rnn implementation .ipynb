{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceefaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26adb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bfec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=requests.get(\"https://storage.googleapis.com/kagglesdsdata/datasets/2371098/3996070/Sonnets.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230927%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230927T152631Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=60fc46d636b7758ac82150347e3427162db4da5d0f43959491ab9397064104a09c0628091730f79e1c9c3cdbd05be24cfdd42c8dc11c2b311fd6f207906619a704f210d5e57dc3484e44a5f9faefd8b92671d5511a240382b4217e95b6cd4c2d642e696529a355ca49f3ba04da9293a2f9729e17b38d5a939090a8cc69ac4d43ad3406ac8151c72f50c60858061846cee661d84535d3659433e3802905106cd9e087bd6aed26c20e6bc6876c0aac7fcb8fe0bd56420e5fc84986d89775b4f15a32b445996cc77b5c94be92f2293f7b96cfca748a93830625aa5f07c56b02f3d107c388aca29f27f4af550709a34df3f30273612b0806ed028413d5f9acbb457f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cd5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6940fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=text.lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b139d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_new=[i for i in corpus if len(i)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a927b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(len(sentence) for sentence in corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70401895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91747d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3406\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)\n",
    "\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668301bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus_new:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label = ku.to_categorical(label, num_classes=total_words+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384d5a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 11, 100)           340700    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 11, 300)          301200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 300)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3406)              344006    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3407)              11607649  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,753,955\n",
      "Trainable params: 12,753,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 01:02:51.732073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:02:51.732810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:02:51.733189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:02:51.776637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-09-28 01:02:51.790393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:02:51.790753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:02:51.791087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:02:51.856296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:02:51.856659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:02:51.856991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words+1, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words+1/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words+1, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4a9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 01:03:22.241640: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-09-28 01:03:22.360750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:22.361152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:22.361507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:22.406942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-09-28 01:03:22.421823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:22.422214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:22.422574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:22.487084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:22.487502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:22.487940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:22.710224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-09-28 01:03:22.912732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:22.913167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:22.913528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:22.962090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-09-28 01:03:22.977395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:22.977808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:22.978174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:23.039233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-09-28 01:03:23.039643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-09-28 01:03:23.040001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-09-28 01:03:23.262384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 25s 44ms/step - loss: 6.4360 - accuracy: 0.1108\n",
      "Epoch 2/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 5.9268 - accuracy: 0.1206\n",
      "Epoch 3/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 5.7798 - accuracy: 0.1264\n",
      "Epoch 4/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 5.6724 - accuracy: 0.1323\n",
      "Epoch 5/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 5.5801 - accuracy: 0.1349\n",
      "Epoch 6/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 5.4877 - accuracy: 0.1390\n",
      "Epoch 7/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 5.4145 - accuracy: 0.1424\n",
      "Epoch 8/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 5.3485 - accuracy: 0.1443\n",
      "Epoch 9/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 5.2892 - accuracy: 0.1454\n",
      "Epoch 10/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 5.2369 - accuracy: 0.1463\n",
      "Epoch 11/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 5.1781 - accuracy: 0.1502\n",
      "Epoch 12/150\n",
      "541/541 [==============================] - 26s 48ms/step - loss: 5.1207 - accuracy: 0.1504\n",
      "Epoch 13/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 5.0519 - accuracy: 0.1540\n",
      "Epoch 14/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 4.9854 - accuracy: 0.1575\n",
      "Epoch 15/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 4.9268 - accuracy: 0.1622\n",
      "Epoch 16/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 4.8604 - accuracy: 0.1675\n",
      "Epoch 17/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 4.7863 - accuracy: 0.1708\n",
      "Epoch 18/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 4.7262 - accuracy: 0.1740\n",
      "Epoch 19/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 4.6608 - accuracy: 0.1781\n",
      "Epoch 20/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 4.5868 - accuracy: 0.1825\n",
      "Epoch 21/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 4.5140 - accuracy: 0.1885\n",
      "Epoch 22/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 4.4371 - accuracy: 0.1965\n",
      "Epoch 23/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 4.3638 - accuracy: 0.1987\n",
      "Epoch 24/150\n",
      "541/541 [==============================] - 28s 51ms/step - loss: 4.2834 - accuracy: 0.2056\n",
      "Epoch 25/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 4.2077 - accuracy: 0.2127\n",
      "Epoch 26/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 4.1318 - accuracy: 0.2179\n",
      "Epoch 27/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 4.0523 - accuracy: 0.2227\n",
      "Epoch 28/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 3.9752 - accuracy: 0.2304\n",
      "Epoch 29/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 3.8894 - accuracy: 0.2387\n",
      "Epoch 30/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 3.8176 - accuracy: 0.2482\n",
      "Epoch 31/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 3.7368 - accuracy: 0.2560\n",
      "Epoch 32/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 3.6626 - accuracy: 0.2702\n",
      "Epoch 33/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 3.5877 - accuracy: 0.2809\n",
      "Epoch 34/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 3.5124 - accuracy: 0.2915\n",
      "Epoch 35/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 3.4440 - accuracy: 0.3030\n",
      "Epoch 36/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 3.3617 - accuracy: 0.3168\n",
      "Epoch 37/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 3.2985 - accuracy: 0.3313\n",
      "Epoch 38/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 3.2203 - accuracy: 0.3490\n",
      "Epoch 39/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 3.1665 - accuracy: 0.3600\n",
      "Epoch 40/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 3.1031 - accuracy: 0.3705\n",
      "Epoch 41/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 3.0437 - accuracy: 0.3852\n",
      "Epoch 42/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.9717 - accuracy: 0.4026\n",
      "Epoch 43/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 2.9204 - accuracy: 0.4140\n",
      "Epoch 44/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 2.8519 - accuracy: 0.4294\n",
      "Epoch 45/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.7939 - accuracy: 0.4403\n",
      "Epoch 46/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 2.7464 - accuracy: 0.4571\n",
      "Epoch 47/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.6932 - accuracy: 0.4637\n",
      "Epoch 48/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.6359 - accuracy: 0.4775\n",
      "Epoch 49/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 2.5899 - accuracy: 0.4915\n",
      "Epoch 50/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 2.5410 - accuracy: 0.4989\n",
      "Epoch 51/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.4867 - accuracy: 0.5105\n",
      "Epoch 52/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.4376 - accuracy: 0.5238\n",
      "Epoch 53/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.3972 - accuracy: 0.5329\n",
      "Epoch 54/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.3620 - accuracy: 0.5392\n",
      "Epoch 55/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 2.3035 - accuracy: 0.5566\n",
      "Epoch 56/150\n",
      "541/541 [==============================] - 28s 51ms/step - loss: 2.2702 - accuracy: 0.5626\n",
      "Epoch 57/150\n",
      "541/541 [==============================] - 29s 54ms/step - loss: 2.2448 - accuracy: 0.5690\n",
      "Epoch 58/150\n",
      "541/541 [==============================] - 28s 52ms/step - loss: 2.1819 - accuracy: 0.5844\n",
      "Epoch 59/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.1463 - accuracy: 0.5882\n",
      "Epoch 60/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 2.1198 - accuracy: 0.5952\n",
      "Epoch 61/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 2.0754 - accuracy: 0.6045\n",
      "Epoch 62/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 2.0427 - accuracy: 0.6144\n",
      "Epoch 63/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 2.0049 - accuracy: 0.6245\n",
      "Epoch 64/150\n",
      "541/541 [==============================] - 30s 56ms/step - loss: 1.9836 - accuracy: 0.6263\n",
      "Epoch 65/150\n",
      "541/541 [==============================] - 27s 51ms/step - loss: 1.9522 - accuracy: 0.6311\n",
      "Epoch 66/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.9167 - accuracy: 0.6443\n",
      "Epoch 67/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.8956 - accuracy: 0.6490\n",
      "Epoch 68/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.8519 - accuracy: 0.6563\n",
      "Epoch 69/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.8315 - accuracy: 0.6613\n",
      "Epoch 70/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.7980 - accuracy: 0.6711\n",
      "Epoch 71/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.7772 - accuracy: 0.6757\n",
      "Epoch 72/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.7441 - accuracy: 0.6799\n",
      "Epoch 73/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 1.7190 - accuracy: 0.6871\n",
      "Epoch 74/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 1.6920 - accuracy: 0.6943\n",
      "Epoch 75/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.6758 - accuracy: 0.6943\n",
      "Epoch 76/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.6442 - accuracy: 0.7059\n",
      "Epoch 77/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 1.6314 - accuracy: 0.7038\n",
      "Epoch 78/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.5993 - accuracy: 0.7129\n",
      "Epoch 79/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.5882 - accuracy: 0.7131\n",
      "Epoch 80/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 1.5637 - accuracy: 0.7196\n",
      "Epoch 81/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.5356 - accuracy: 0.7261\n",
      "Epoch 82/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.5245 - accuracy: 0.7272\n",
      "Epoch 83/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 1.4986 - accuracy: 0.7324\n",
      "Epoch 84/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.4708 - accuracy: 0.7418\n",
      "Epoch 85/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.4592 - accuracy: 0.7398\n",
      "Epoch 86/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.4504 - accuracy: 0.7415\n",
      "Epoch 87/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 1.4327 - accuracy: 0.7450\n",
      "Epoch 88/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.4191 - accuracy: 0.7483\n",
      "Epoch 89/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.3975 - accuracy: 0.7566\n",
      "Epoch 90/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 1.3836 - accuracy: 0.7562\n",
      "Epoch 91/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.3613 - accuracy: 0.7627\n",
      "Epoch 92/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.3512 - accuracy: 0.7632\n",
      "Epoch 93/150\n",
      "541/541 [==============================] - 23s 43ms/step - loss: 1.3309 - accuracy: 0.7685\n",
      "Epoch 94/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.3149 - accuracy: 0.7704\n",
      "Epoch 95/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.3004 - accuracy: 0.7723\n",
      "Epoch 96/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.2958 - accuracy: 0.7725\n",
      "Epoch 97/150\n",
      "541/541 [==============================] - 24s 43ms/step - loss: 1.2832 - accuracy: 0.7744\n",
      "Epoch 98/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.2640 - accuracy: 0.7790\n",
      "Epoch 99/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.2419 - accuracy: 0.7839\n",
      "Epoch 100/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 1.2386 - accuracy: 0.7836\n",
      "Epoch 101/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.2325 - accuracy: 0.7853\n",
      "Epoch 102/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.2228 - accuracy: 0.7872\n",
      "Epoch 103/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 1.1986 - accuracy: 0.7950\n",
      "Epoch 104/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.1886 - accuracy: 0.7917\n",
      "Epoch 105/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.1958 - accuracy: 0.7913\n",
      "Epoch 106/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.1802 - accuracy: 0.7926\n",
      "Epoch 107/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 1.1673 - accuracy: 0.7992\n",
      "Epoch 108/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.1552 - accuracy: 0.8007\n",
      "Epoch 109/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 1.1409 - accuracy: 0.8043\n",
      "Epoch 110/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.1276 - accuracy: 0.8022\n",
      "Epoch 111/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.1228 - accuracy: 0.8038\n",
      "Epoch 112/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.1222 - accuracy: 0.8043\n",
      "Epoch 113/150\n",
      "541/541 [==============================] - 27s 49ms/step - loss: 1.1188 - accuracy: 0.8026\n",
      "Epoch 114/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.1005 - accuracy: 0.8104\n",
      "Epoch 115/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.0839 - accuracy: 0.8116\n",
      "Epoch 116/150\n",
      "541/541 [==============================] - 28s 51ms/step - loss: 1.0791 - accuracy: 0.8128\n",
      "Epoch 117/150\n",
      "541/541 [==============================] - 27s 49ms/step - loss: 1.0738 - accuracy: 0.8132\n",
      "Epoch 118/150\n",
      "541/541 [==============================] - 26s 49ms/step - loss: 1.0781 - accuracy: 0.8128\n",
      "Epoch 119/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.0683 - accuracy: 0.8149\n",
      "Epoch 120/150\n",
      "541/541 [==============================] - 27s 50ms/step - loss: 1.0584 - accuracy: 0.8150\n",
      "Epoch 121/150\n",
      "541/541 [==============================] - 28s 51ms/step - loss: 1.0420 - accuracy: 0.8187\n",
      "Epoch 122/150\n",
      "541/541 [==============================] - 27s 51ms/step - loss: 1.0439 - accuracy: 0.8170\n",
      "Epoch 123/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 1.0333 - accuracy: 0.8188\n",
      "Epoch 124/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 1.0262 - accuracy: 0.8209\n",
      "Epoch 125/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.0226 - accuracy: 0.8239\n",
      "Epoch 126/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 1.0197 - accuracy: 0.8236\n",
      "Epoch 127/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 1.0106 - accuracy: 0.8234\n",
      "Epoch 128/150\n",
      "541/541 [==============================] - 25s 45ms/step - loss: 1.0087 - accuracy: 0.8244\n",
      "Epoch 129/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 0.9941 - accuracy: 0.8263\n",
      "Epoch 130/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9866 - accuracy: 0.8285\n",
      "Epoch 131/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 0.9834 - accuracy: 0.8306\n",
      "Epoch 132/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 0.9778 - accuracy: 0.8292\n",
      "Epoch 133/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 0.9712 - accuracy: 0.8288\n",
      "Epoch 134/150\n",
      "541/541 [==============================] - 26s 49ms/step - loss: 0.9849 - accuracy: 0.8255\n",
      "Epoch 135/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 0.9718 - accuracy: 0.8299\n",
      "Epoch 136/150\n",
      "541/541 [==============================] - 26s 49ms/step - loss: 0.9640 - accuracy: 0.8288\n",
      "Epoch 137/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9512 - accuracy: 0.8335\n",
      "Epoch 138/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9612 - accuracy: 0.8280\n",
      "Epoch 139/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 0.9374 - accuracy: 0.8340\n",
      "Epoch 140/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 0.9441 - accuracy: 0.8327\n",
      "Epoch 141/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9381 - accuracy: 0.8341\n",
      "Epoch 142/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 0.9385 - accuracy: 0.8328\n",
      "Epoch 143/150\n",
      "541/541 [==============================] - 29s 53ms/step - loss: 0.9377 - accuracy: 0.8320\n",
      "Epoch 144/150\n",
      "541/541 [==============================] - 26s 48ms/step - loss: 0.9236 - accuracy: 0.8347\n",
      "Epoch 145/150\n",
      "541/541 [==============================] - 26s 47ms/step - loss: 0.9171 - accuracy: 0.8368\n",
      "Epoch 146/150\n",
      "541/541 [==============================] - 25s 47ms/step - loss: 0.9166 - accuracy: 0.8354\n",
      "Epoch 147/150\n",
      "541/541 [==============================] - 24s 45ms/step - loss: 0.9123 - accuracy: 0.8379\n",
      "Epoch 148/150\n",
      "541/541 [==============================] - 24s 44ms/step - loss: 0.9079 - accuracy: 0.8365\n",
      "Epoch 149/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9054 - accuracy: 0.8384\n",
      "Epoch 150/150\n",
      "541/541 [==============================] - 25s 46ms/step - loss: 0.9015 - accuracy: 0.8387\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf91bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \r\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"I love not less though less\"\n",
    "num_words_to_generate = 50\n",
    "generated_words = seed_text.split()\n",
    "\n",
    "while len(generated_words) < num_words_to_generate:\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probabilities = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted_probabilities)\n",
    "    predicted_word = None\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            predicted_word = word\n",
    "            break\n",
    "    generated_words.append(predicted_word)\n",
    "    seed_text += \" \" + predicted_word\n",
    "\n",
    "generated_text = ' '.join(generated_words)\n",
    "print(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96cfc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \r\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"I love not less though less\"\n",
    "num_words_to_generate = 50\n",
    "generated_words = seed_text.split()\n",
    "\n",
    "while len(generated_words) < num_words_to_generate:\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probabilities = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted_probabilities)\n",
    "    predicted_word = None\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            predicted_word = word\n",
    "            break\n",
    "    generated_words.append(predicted_word)\n",
    "    seed_text += \" \" + predicted_word\n",
    "\n",
    "generated_text = ' '.join(generated_words)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee0a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158517f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317dcbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485d29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664eb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2e0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8cfb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247d2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32117d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fe97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
